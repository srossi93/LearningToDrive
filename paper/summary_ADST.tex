\documentclass[10pt,journal,compsoc]{IEEEtran}
% *** MISC UTILITY PACKAGES ***
%
%\usepackage{ifpdf}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/pkg/ifpdf
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.






% *** CITATION PACKAGES ***
%
\ifCLASSOPTIONcompsoc
  % The IEEE Computer Society needs nocompress option
  % requires cite.sty v4.0 or later (November 2003)
  \usepackage[nocompress]{cite}
\else
  % normal IEEE
  \usepackage{cite}
\fi



% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
   \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi


% *** MATH PACKAGES ***
%
\usepackage{amsmath}
% Note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500


\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as the IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions.



% *** SUBFIGURE PACKAGES ***
\ifCLASSOPTIONcompsoc
  \usepackage[caption=false,font=footnotesize,labelfont=sf,textfont=sf]{subfig}
\else
  \usepackage[caption=false,font=footnotesize]{subfig}
\fi
% subfig.sty, written by Steven Douglas Cochran, is the modern replacement
% for subfigure.sty, the latter of which is no longer maintained and is
% incompatible with some LaTeX packages including fixltx2e. However,
% subfig.sty requires and automatically loads Axel Sommerfeldt's caption.sty
% which will override IEEEtran.cls' handling of captions and this will result
% in non-IEEE style figure/table captions. To prevent this problem, be sure
% and invoke subfig.sty's "caption=false" package option (available since
% subfig.sty version 1.3, 2005/06/28) as this is will preserve IEEEtran.cls
% handling of captions.
% Note that the Computer Society format requires a sans serif font rather
% than the serif font used in traditional IEEE formatting and thus the need
% to invoke different subfig.sty package options depending on whether
% compsoc mode has been enabled.
%
% The latest version and documentation of subfig.sty can be obtained at:
% http://www.ctan.org/pkg/subfig




% *** PDF, URL AND HYPERLINK PACKAGES ***
%
\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/url
% Basically, \url{my_url_here}.


% NOTE: PDF thumbnail features are not required in IEEE papers
%       and their use requires extra complexity and work.
\ifCLASSINFOpdf
  \usepackage[pdftex]{thumbpdf}
\else
  \usepackage[dvips]{thumbpdf}
\fi
% thumbpdf.sty and its companion Perl utility were written by Heiko Oberdiek.
% It allows the user a way to produce PDF documents that contain fancy
% thumbnail images of each of the pages (which tools like acrobat reader can
% utilize). This is possible even when using dvi->ps->pdf workflow if the
% correct thumbpdf driver options are used. thumbpdf.sty incorporates the
% file containing the PDF thumbnail information (filename.tpm is used with
% dvips, filename.tpt is used with pdftex, where filename is the base name of
% your tex document) into the final ps or pdf output document. An external
% utility, the thumbpdf *Perl script* is needed to make these .tpm or .tpt
% thumbnail files from a .ps or .pdf version of the document (which obviously
% does not yet contain pdf thumbnails). Thus, one does a:
%
% thumbpdf filename.pdf
%
% to make a filename.tpt, and:
%
% thumbpdf --mode dvips filename.ps
%
% to make a filename.tpm which will then be loaded into the document by
% thumbpdf.sty the NEXT time the document is compiled (by pdflatex or
% latex->dvips->ps2pdf). Users must be careful to regenerate the .tpt and/or
% .tpm files if the main document changes and then to recompile the
% document to incorporate the revised thumbnails to ensure that thumbnails
% match the actual pages. It is easy to forget to do this!
%
% Unix systems come with a Perl interpreter. However, MS Windows users
% will usually have to install a Perl interpreter so that the thumbpdf
% script can be run. The Ghostscript PS/PDF interpreter is also required.
% See the thumbpdf docs for details. The latest version and documentation
% can be obtained at.
% http://www.ctan.org/pkg/thumbpdf


% NOTE: PDF hyperlink and bookmark features are not required in IEEE
%       papers and their use requires extra complexity and work.
% *** IF USING HYPERREF BE SURE AND CHANGE THE EXAMPLE PDF ***
% *** TITLE/SUBJECT/AUTHOR/KEYWORDS INFO BELOW!!           ***
\newcommand\MYhyperrefoptions{bookmarks=true,bookmarksnumbered=true,
pdfpagemode={UseOutlines},plainpages=false,pdfpagelabels=true,
colorlinks=true,linkcolor={black},citecolor={black},urlcolor={black},
pdftitle={Bare Demo of IEEEtran.cls for Computer Society Journals},%<!CHANGE!
pdfsubject={Typesetting},%<!CHANGE!
pdfauthor={Michael D. Shell},%<!CHANGE!
pdfkeywords={Computer Society, IEEEtran, journal, LaTeX, paper,
             template}}%<^!CHANGE!
\ifCLASSINFOpdf
    \usepackage[\MYhyperrefoptions,pdftex]{hyperref}
\else
    \usepackage[\MYhyperrefoptions,breaklinks=true,dvips]{hyperref}
    \usepackage{breakurl}
\fi
% One significant drawback of using hyperref under DVI output is that the
% LaTeX compiler cannot break URLs across lines or pages as can be done
% under pdfLaTeX's PDF output via the hyperref pdftex driver. This is
% probably the single most important capability distinction between the
% DVI and PDF output. Perhaps surprisingly, all the other PDF features
% (PDF bookmarks, thumbnails, etc.) can be preserved in
% .tex->.dvi->.ps->.pdf workflow if the respective packages/scripts are
% loaded/invoked with the correct driver options (dvips, etc.).
% As most IEEE papers use URLs sparingly (mainly in the references), this
% may not be as big an issue as with other publications.




% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}
\linespread{1.032}

\begin{document}
%
% paper title
\title{Learning To Drive\\ Pedestrian Detection for Self Driving Cars}
%

\author{Simone Rossi, Matteo Romiti}


% The paper headers
\markboth{Summary for the mini conference on Advanced Data Science Topics}%
{Shell \MakeLowercase{\textit{et al.}}: Bare Advanced Demo of IEEEtran.cls for IEEE Computer Society Journals}

\IEEEtitleabstractindextext{%

%\begin{abstract}
%The abstract goes here.
%\end{abstract}

% Note that keywords are not normally used for peerreview papers.
\begin{IEEEkeywords}
Self-driving cars, Histograms of Oriented Gradients, Probabilistic Part-based Models,
Convolutional Neural Networks, Deep Learning
\end{IEEEkeywords}}


% make the title area
\maketitle


% To allow for easy dual compilation without having to reenter the
% abstract/keywords data, the \IEEEtitleabstractindextext text will
% not be used in maketitle, but will appear (i.e., to be "transported")
% here as \IEEEdisplaynontitleabstractindextext when compsoc mode
% is not selected <OR> if conference mode is selected - because compsoc
% conference papers position the abstract like regular (non-compsoc)
% papers do!
\IEEEdisplaynontitleabstractindextext
% \IEEEdisplaynontitleabstractindextext has no effect when using
% compsoc under a non-conference mode.


% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle



\section{Introduction}
\label{sec:introduction}

\IEEEPARstart{S}{elf-driving cars} are increasingly gaining momentum in the
recent years due to unprecedented activity, and excitement in the field
of intelligent vehicles. The culmination of
research efforts of the past decades in a broad range of disciplines, including
vehicle control, robotics, sensing, machine perception, navigation, mapping,
machine learning, embedded systems, human-machine interactivity, and human factors,
has realized practical and affordable systems for various automated features in
automobiles. This advancement is opening doors to possibilities only thought to
be fictional a few decades ago. The aim of this work is to recognize the next set
of research challenges required to be addressed for achieving highly reliable,
fail-safe, intelligent vehicles which can earn the trust of humans who would
ultimately purchase and use these vehicles.

Among all issues that the next generation of self-driving cars should solve, this
presentation is focused on the pedestrian detection. Detecting pedestrians is, in fact,
a challenging task for a machine perception due to pedestrian’s different
clothing, various poses and positions, variable lighting conditions, unstructured
environment and various parts of the pedestrian may occlude, making it difficult
to represent a pedestrian. We report some of the technologies available to tackle
this challenging task such as Histograms of Oriented Gradients, Partial Occlusion
Handling for Part-based Models and Convolutional Neural Networks and finally we
provide both examples and comparisons on their performances.

\hfill Jan. 5, 2017



\section{Histograms of Oriented Gradients}
\label{sec:HOG}
\IEEEPARstart{H}{istograms of Oriented Gradients} is one of the most well known methods for feature
extraction for human detection in computer vision, it is very versatile and it
can be applied in different contexts. The basic idea is that local object appearance
and shape can often be characterized rather well by the distribution of local
intensity gradients or edge directions, even without precise knowledge of the
corresponding gradient or edge positions.

This is done by dividing the image grid of pixels into small spatial regions (cells),
accumulating a 1D histogram of gradient directions over all pixels of a cell and,
finally, normalizing the result over a block of cells for better invariance to illumination.

This feature extractor has shown that
locally normalized histogram of gradient orientations applied to a dense overlapping
grid of pixes gives very good results for person detection, with the best result of
10.4\% miss rate with 3$\times$3 blocks of 6$\times$6 pixel cells.

% needed in second column of first page if using \IEEEpubid
%\IEEEpubidadjcol

\section{Part-based Models for Object Detection}
\label{sec:part_based_model}
\IEEEPARstart{P}{art-based Model} is a framework that represents highly variable
objects using mixtures of multiscale deformable parts.
This approach builds on the pictorial structures framework. Pictorial structures
represent objects by a collection of parts arranged in a deformable configuration.
Each part captures local appearance properties of an object while the deformable
configuration is characterized by connections between certain pairs of parts.

For the scope of this presentation, we are interested only in the way in which parts
are modeled and how they are used to create the final descriptors.
These star models are defined by a coarse root detector that approximately covers an
entire object and higher resolution part detectors that cover smaller parts of the
object. The root detector location defines a detection window (the pixels contributing to
the region of the feature map). The part detectors are computed at twice the resolution
of the features in the root level.
It has been studied that using higher resolution features for defining parts is essential
for obtaining high recognition performance. With this approach, the part detectors
capture finer resolution features that are localized to greater accuracy when
compared to the features captured by the root filter.




\section{Deep Model-based Solution for Partial Occlusion in Pedestrian Detection}
\label{sec:Occ}
\IEEEPARstart{O}{cclusion} for Pedestrian Detection is a key issue that previous models
does not take into account; in fact generic detectors (such as HOGs) assume that
pedestrians are fully visible and their performance degrades when pedestrians are
partially occluded. Deformable part-based models, like the one aforementioned in
Section \ref{sec:part_based_model}, sums the scores of part detectors.
If one part is occluded, the score of its part detector could be very low, and
consequently, the summed score will also be low.
However, occlusions occur frequently, especially in crowded scenes.

The solution proposed for handling the partially occluded pedestrian comes with two contributions:
a probabilistic framework, which models the visibilities
of parts as hidden variables, and a deep model to learn the visibility correlations
of different parts. The hierarchical structure of this deep model matches with
the multilayers of the parts model. Differently from the generic deep networks,
whose hidden variables had no semantic meaning, this model considers each hidden
variable as representing the visibility of a part. By including multiple layers,
the deep model achieves a more reliable visibility estimation.

As expected, this method overcomes all the previous one in case of occluded
subject: for instance, on the Daimler occlusion dataset, HOG performs with less
than 20\%, while this deep network, once trained, detected more than 60\% of the
total subjects under test.

\section{Convolutional Neural Networks for Pedestrian Detection}
\label{sec:CNN}
\IEEEPARstart{C}{onvolutional Neural Networks} (CNNs) emerged as the state of the art in terms of
accuracy for computer vision tasks such as: image classification, object detection,
face recognition. The downside is that they are based on very complex models with
hundreds of millions of parameters and usually need large training datasets.
Differently from regular neural networks, CNNs assume that the inputs are images,
allowing layers to have neurons arranged in 3 dimensions: width, height, depth.
In general, we have the following layers: convolutional layer, non-linear layer,
pooling layer, fully-connected layer. They can also be repeated and placed in a cascade.

In the convolutional layer, we have an input matrix representing the image to analyze
and another smaller matrix, named filter or kernel. The result of this layer is the
convolution of these two matrices obtained by sliding the filter on the input matrix
and the output is a map, called feature map, which depends on: the filter values, the
step between each convolution and the size of the filter. Changing these parameters,
we get different feature maps. The pooling layer is instead used to reduce the dimensionality
of the feature map. This is achieved by splitting the feature map into different blocks
and performing a downsampling operation like Max, Average, Sum on each block, which
means that each block will be mapped to the max value, average value, or sum value.
The fully-connected layer is a classifier that computes the class scores.
In pedestrian detection tasks, CNNs require some modifications to increase accuracy
and speed. We report here two of the best performing models considering accuracy and speed.

\subsection{DeepPed}
\label{sub:DeepPed}

The first model is named DeepPed. As region proposal method, it uses Locally
Decorrelated Channel Features (LDCF), an ad-hoc pedestrian detection algorithm
where the output is possibly large set of regions each with a confidence value
and setting a threshold on the confidence score allows for a tradeoff between
precision and recall. Secondly, a fine-tuned CNN (AlexNet) acts as a feature
extractor and finally a SVM, using the LCDF confidence scores, is the final
classifier. To achieve high accuracy (19.9\% of Miss Rate at 2 fps), they introduce
some data preprocessing, namely: padding to overcome the issue of imprecise proposed
region, and negative sample decorrelation to get higher quality (more diverse) input data.
The padding process works roughly in this way: for each box of the training dataset,
 select the closest candidate region, compute the padding needed so that the box
 is contained in the region, build the histogram of the padding quantities and then
 use the mean value. The decorrelation process follows this approach: randomly
 extract N regions not containing a pedestrian, compute their color histogram,
 normalize it to obtain a probability distribution, compute the euclidean
 distance between each pair of distributions, and select the furthest apart K regions.
 figure \ref{sub:DeepPed}
\subsection{DeepCascade}
 \label{sub:DeepCascade}

 The second model comes from Google’s researchers. DeepCascade aims at a real-time
 pedestrian detection technology (15 fps), still with a good accuracy (26.2\% Miss Rate).
  They used two CNNs and soft-cascade to speed up the classification process.
  The first CNN is a tiny Deep Neural Network classifier with the following stages:
  convolutional, pooling, convolutional, fully-connected, dropout and fully-connected,
  while the second is AlexNet, properly modified to decrease the computational time.
  The authors also added some pre-training: the weights are initialized from a
  network trained on Imagenet, which increases accuracy. The key role is played
  by the soft-cascade approach which is able to reject negative patches very quickly.





% An example of a floating figure using the graphicx package.
% Note that \label must occur AFTER (or within) \caption.
% For figures, \caption should occur after the \includegraphics.
% Note that IEEEtran v1.7 and later has special internal code that
% is designed to preserve the operation of \label within \caption
% even when the captionsoff option is in effect. However, because
% of issues like this, it may be the safest practice to put all your
% \label just after \caption rather than within \caption{}.
%
% Reminder: the "draftcls" or "draftclsnofoot", not "draft", class
% option should be used if it is desired that the figures are to be
% displayed while in draft mode.
%
%\begin{figure}[!t]
%\centering
%\includegraphics[width=2.5in]{myfigure}
% where an .eps filename suffix will be assumed under latex,
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
%\caption{Simulation results for the network.}
%\label{fig_sim}
%\end{figure}

% Note that the IEEE typically puts floats only at the top, even when this
% results in a large percentage of a column being occupied by floats.
% However, the Computer Society has been known to put floats at the bottom.


% An example of a double column floating figure using two subfigures.
% (The subfig.sty package must be loaded for this to work.)
% The subfigure \label commands are set within each subfloat command,
% and the \label for the overall figure must come after \caption.
% \hfil is used as a separator to get equal spacing.
% Watch out that the combined width of all the subfigures on a
% line do not exceed the text width or a line break will occur.
%
%\begin{figure*}[!t]
%\centering
%\subfloat[Case I]{\includegraphics[width=2.5in]{box}%
%\label{fig_first_case}}
%\hfil
%\subfloat[Case II]{\includegraphics[width=2.5in]{box}%
%\label{fig_second_case}}
%\caption{Simulation results for the network.}
%\label{fig_sim}
%\end{figure*}
%
% Note that often IEEE papers with subfigures do not employ subfigure
% captions (using the optional argument to \subfloat[]), but instead will
% reference/describe all of them (a), (b), etc., within the main caption.
% Be aware that for subfig.sty to generate the (a), (b), etc., subfigure
% labels, the optional argument to \subfloat must be present. If a
% subcaption is not desired, just leave its contents blank,
% e.g., \subfloat[].


% An example of a floating table. Note that, for IEEE style tables, the
% \caption command should come BEFORE the table and, given that table
% captions serve much like titles, are usually capitalized except for words
% such as a, an, and, as, at, but, by, for, in, nor, of, on, or, the, to
% and up, which are usually not capitalized unless they are the first or
% last word of the caption. Table text will default to \footnotesize as
% the IEEE normally uses this smaller font for tables.
% The \label must come after \caption as always.
%
%\begin{table}[!t]
%% increase table row spacing, adjust to taste
%\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
%\caption{An Example of a Table}
%\label{table_example}
%\centering
%% Some packages, such as MDW tools, offer better commands for making tables
%% than the plain LaTeX2e tabular which is used here.
%\begin{tabular}{|c||c|}
%\hline
%One & Two\\
%\hline
%Three & Four\\
%\hline
%\end{tabular}
%\end{table}


% Note that the IEEE does not put floats in the very first column
% - or typically anywhere on the first page for that matter. Also,
% in-text middle ("here") positioning is typically not used, but it
% is allowed and encouraged for Computer Society conferences (but
% not Computer Society journals). Most IEEE journals/conferences use
% top floats exclusively.
% Note that, LaTeX2e, unlike IEEE journals/conferences, places
% footnotes above bottom floats. This can be corrected via the
% \fnbelowfloat command of the stfloats package.




\section{Conclusion}
In this work, we presented different approaches to detect pedestrians, trying to
underline strengths and weaknesses. They are and will play a key-role in the future
of self-driving cars, both for the safety of the pedestrians and for the safety
of the people in the car, reason why we are interested in improving and contributing
to this research field.






% if have a single appendix:
%\appendix[Proof of the Zonklar Equations]
% or
%\appendix  % for no appendix heading
% do not use \section anymore after \appendix, only \section*
% is possibly needed

% use appendices with more than one appendix
% then use \section to start each appendix
% you must declare a \section before using any
% \subsection or using \label (\appendices by itself
% starts a section numbered zero.)
%

% Can use something like this to put references on a page
% by themselves when using endfloat and the captionsoff option.
\ifCLASSOPTIONcaptionsoff
  \newpage
\fi



% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://mirror.ctan.org/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
%\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)
%\begin{thebibliography}{1}

 %\bibliographystyle{acm}
 \bibliographystyle{IEEEtran}
 \nocite{*}
 \bibliography{Bibliography}

%\bibitem{IEEEhowto:kopka}
%H.~Kopka and P.~W. Daly, \emph{A Guide to {\LaTeX}}, 3rd~ed.\hskip 1em plus%
%  0.5em minus 0.4em\relax Harlow, England: Addison-Wesley, 1999.

%\end{thebibliography}

% biography section
%
% If you have an EPS/PDF photo (graphicx package needed) extra braces are
% needed around the contents of the optional argument to biography to prevent
% the LaTeX parser from getting confused when it sees the complicated
% \includegraphics command within an optional argument. (You could create
% your own custom macro containing the \includegraphics command to make things
% simpler here.)
%\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{mshell}}]{Michael Shell}
% or if you just want to reserve a space for a photo:



% You can push biographies down or up by placing
% a \vfill before or after them. The appropriate
% use of \vfill depends on what kind of text is
% on the last page and whether or not the columns
% are being equalized.

%\vfill

% Can be used to pull up biographies so that the bottom of the last one
% is flush with the other column.
%\enlargethispage{-5in}



% that's all folks
\end{document}
